{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84b9b84f",
   "metadata": {},
   "source": [
    "## Machine Learning with Apache Spark\n",
    "### Final Project\n",
    "**Project Description**\n",
    "\n",
    "The main goal is to clean the dataset, build a machine learning pipeline, evaluate the model and make the model persist for future use.\n",
    "\n",
    "**Project Phases**\n",
    "1. Data cleaning\n",
    "    - Remove duplicates.\n",
    "    - Handle missing values.\n",
    "    - Fix some other defects.\n",
    "    - Save the cleaned data in parquet format.\n",
    "2. Build machine learning pipeline stages\n",
    "    - Assemble features in one vector.\n",
    "    - Assign categorical attributes to indices.\n",
    "    - Scale the variables to prevent model bias.\n",
    "    - Build the regression model stage.\n",
    "    - Build the pipeline with the mentioned stages.\n",
    "3. Evaluation Phase\n",
    "    - Use evaluation metrics.\n",
    "4. Saving the model\n",
    "    - Make the model persist for future use, portability and time consuming.\n",
    "    - Save the model.\n",
    "    - Load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "fb57de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession, functions as F, types as T\n",
    "from pyspark.ml.feature import VectorAssembler,  StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.pipeline import PipelineModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2ce771a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Final Project').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c4d390",
   "metadata": {},
   "source": [
    "#### Part 1\n",
    "1. Download data.\n",
    "2. Load it to spark dataframe.\n",
    "3. Remove duplicates.\n",
    "4. Remove rows contain nulls.\n",
    "5. Save data in parquet format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da164c58",
   "metadata": {},
   "source": [
    "Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7c66fd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "if ! test -d data;then\n",
    "    mkdir data\n",
    "fi\n",
    "fileName=\"NASA_airfoil_noise_raw.csv\"\n",
    "if ! test -f data/$fileName;then\n",
    "    wget -P data https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-BD0231EN-Coursera/datasets/NASA_airfoil_noise_raw.csv\n",
    "else\n",
    "    echo \"File exists\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "079b2f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Frequency: integer (nullable = true)\n",
      " |-- AngleOfAttack: double (nullable = true)\n",
      " |-- ChordLength: double (nullable = true)\n",
      " |-- FreeStreamVelocity: double (nullable = true)\n",
      " |-- SuctionSideDisplacement: double (nullable = true)\n",
      " |-- SoundLevel: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fileName='NASA_airfoil_noise_raw.csv'\n",
    "df = spark.read.csv(f'data/{fileName}',header=True, inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ae4cbf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----------+------------------+-----------------------+----------+\n",
      "|Frequency|AngleOfAttack|ChordLength|FreeStreamVelocity|SuctionSideDisplacement|SoundLevel|\n",
      "+---------+-------------+-----------+------------------+-----------------------+----------+\n",
      "|      800|          0.0|     0.3048|              71.3|             0.00266337|   126.201|\n",
      "|     1000|          0.0|     0.3048|              71.3|             0.00266337|   125.201|\n",
      "|     1250|          0.0|     0.3048|              71.3|             0.00266337|   125.951|\n",
      "|     1600|          0.0|     0.3048|              71.3|             0.00266337|   127.591|\n",
      "|     2000|          0.0|     0.3048|              71.3|             0.00266337|   127.461|\n",
      "+---------+-------------+-----------+------------------+-----------------------+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7dbb61",
   "metadata": {},
   "source": [
    "Print all records containing null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f4e24e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----------+------------------+-----------------------+----------+-----+\n",
      "|Frequency|AngleOfAttack|ChordLength|FreeStreamVelocity|SuctionSideDisplacement|SoundLevel|nulls|\n",
      "+---------+-------------+-----------+------------------+-----------------------+----------+-----+\n",
      "|     NULL|          0.0|     0.3048|              55.5|             0.00283081|   123.236|    1|\n",
      "|      630|          0.0|     0.3048|              NULL|             0.00310138|   128.629|    1|\n",
      "|     2500|          1.5|     0.3048|              NULL|             0.00392107|   120.981|    1|\n",
      "|      800|          3.0|       NULL|              39.6|             0.00495741|   129.552|    1|\n",
      "+---------+-------------+-----------+------------------+-----------------------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "expr = sum(F.when(F.col(x).isNull(),1).otherwise(0) for x in df.columns)\n",
    "df.withColumn('nulls', expr).filter(F.col('nulls') != 0).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca24cea",
   "metadata": {},
   "source": [
    "### How to handle null values?\n",
    "There are more than one way to handle it, according to the requirements and the dataset itself so either:\n",
    "1. Remove the whole record.\n",
    "2. Replace the null values by the mean of that attribute in the whole dataset (if the variable is numberic).\n",
    "3. Replace it by the median.\n",
    "4. For categorical attributes you may replace nulls with the mode.\n",
    "\n",
    "> In this we will remove the whole record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "25d55fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records of original data set = 1522\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of records of original data set = {df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "2964de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "18b6ee52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----------+------------------+-----------------------+----------+-----+\n",
      "|Frequency|AngleOfAttack|ChordLength|FreeStreamVelocity|SuctionSideDisplacement|SoundLevel|nulls|\n",
      "+---------+-------------+-----------+------------------+-----------------------+----------+-----+\n",
      "+---------+-------------+-----------+------------------+-----------------------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('nulls', expr).filter(F.col('nulls') != 0).show()\n",
    "#Now there is no null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "47ed4be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records after removing rows contain null values = 1518\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of records after removing rows contain null values = {df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "4137d723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Frequency',\n",
       " 'AngleOfAttack',\n",
       " 'ChordLength',\n",
       " 'FreeStreamVelocity',\n",
       " 'SuctionSideDisplacement',\n",
       " 'SoundLevelDecibels']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rename column\n",
    "df = df.withColumnRenamed('SoundLevel','SoundLevelDecibels')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5fa94862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records number after removing duplicates = 1499\n"
     ]
    }
   ],
   "source": [
    "df  = df.dropDuplicates()\n",
    "print(f\"Records number after removing duplicates = {df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deec9b02",
   "metadata": {},
   "source": [
    "Save the cleaned dataframe in the parquet formate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "63a5436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode('overwrite').parquet(f'data/{fileName}_cleaned.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6c863a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbfd4ad",
   "metadata": {},
   "source": [
    "#### Part 2 (Building the pipeline)\n",
    "1. Load data from the parquet format.\n",
    "2. Define assembler stage.\n",
    "3. Define scaler stage.\n",
    "4. Define linear regression model stage.\n",
    "5. Build the pipeline.\n",
    "6. Split the dataset into training and testing sets.\n",
    "7. Fit the pipeline using training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "9d23e718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Frequency: integer (nullable = true)\n",
      " |-- AngleOfAttack: double (nullable = true)\n",
      " |-- ChordLength: double (nullable = true)\n",
      " |-- FreeStreamVelocity: double (nullable = true)\n",
      " |-- SuctionSideDisplacement: double (nullable = true)\n",
      " |-- SoundLevelDecibels: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(f'data/{fileName}_cleaned.parquet')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2fc128d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1499"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b1648bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Frequency', 'AngleOfAttack', 'ChordLength', 'FreeStreamVelocity', 'SuctionSideDisplacement', 'SoundLevelDecibels']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "42ef0bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 1: Assembler\n",
    "features_columns  = df.columns[:-1]\n",
    "assembler= VectorAssembler(inputCols=features_columns, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e58391ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 2: Scaler\n",
    "scaler = StandardScaler(inputCol='features',outputCol='scaled_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4e7a935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stage 3: LinearRegression\n",
    "lr = LinearRegression(featuresCol='scaled_features',labelCol='SoundLevelDecibels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "cbe21278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the pipeline\n",
    "pipeline = Pipeline(stages=[assembler, scaler, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b3c2ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset\n",
    "training_data, testing_data = df.randomSplit([0.7,0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9c4f95a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1101\n",
      "398\n"
     ]
    }
   ],
   "source": [
    "print(training_data.count())\n",
    "print(testing_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d496ee34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/14 22:06:34 WARN Instrumentation: [d81bf7c1] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    }
   ],
   "source": [
    "#Fit the pipeline\n",
    "model = pipeline.fit(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a2e66814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2 - Evaluation\n",
      "Total rows =  1499\n",
      "Pipeline Stage 1 =  VectorAssembler\n",
      "Pipeline Stage 2 =  StandardScaler\n",
      "Pipeline Stage 3 =  LinearRegression\n",
      "Label column =  SoundLevelDecibels\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 2 - Evaluation\")\n",
    "print(\"Total rows = \", df.count())\n",
    "ps = [str(x).split(\"_\")[0] for x in pipeline.getStages()]\n",
    "\n",
    "print(\"Pipeline Stage 1 = \", ps[0])\n",
    "print(\"Pipeline Stage 2 = \", ps[1])\n",
    "print(\"Pipeline Stage 3 = \", ps[2])\n",
    "\n",
    "print(\"Label column = \", lr.getLabelCol())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c07a3a9",
   "metadata": {},
   "source": [
    "#### Part 3 (Evaluation)\n",
    "1. Predict the testing data using the model.\n",
    "2. Show some of linear regression evaluation metrics.\n",
    "    - MSE\n",
    "    - MAE\n",
    "    - R-Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "1be4bb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions  = model.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "eda4abba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Frequency', 'AngleOfAttack', 'ChordLength', 'FreeStreamVelocity', 'SuctionSideDisplacement', 'SoundLevelDecibels', 'features', 'scaled_features', 'prediction']\n"
     ]
    }
   ],
   "source": [
    "print(predictions.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "65aefcd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|SoundLevelDecibels|        prediction|\n",
      "+------------------+------------------+\n",
      "|           128.679| 122.5972291437678|\n",
      "|            133.42|127.37968204568845|\n",
      "|           119.146|130.34077425074514|\n",
      "|           116.074|131.11016975113546|\n",
      "|           134.319|  127.126273601251|\n",
      "|            125.01|127.89456373905162|\n",
      "|           125.941|131.06220981224092|\n",
      "|           130.588| 125.7373995384845|\n",
      "|           128.354|121.53249832197926|\n",
      "|           121.783|124.20059665619317|\n",
      "|            122.94|125.87997778533574|\n",
      "|           116.146|125.24362112904097|\n",
      "|           114.044|126.06429872612996|\n",
      "|           109.951|127.67830278943781|\n",
      "|           125.974|121.25022147564815|\n",
      "|           116.066|123.31966959832607|\n",
      "|           118.595|124.20046348885941|\n",
      "|           126.395|126.16068839641792|\n",
      "|           130.089| 122.5337859220606|\n",
      "|           131.889|123.42922049990017|\n",
      "+------------------+------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "predictions.select(['SoundLevelDecibels','prediction']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "be136fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol='SoundLevelDecibels', predictionCol='prediction', metricName='mse')\n",
    "mse = evaluator.evaluate(predictions)\n",
    "evaluator = RegressionEvaluator(labelCol='SoundLevelDecibels', predictionCol='prediction', metricName='mae')\n",
    "mae = evaluator.evaluate(predictions)\n",
    "evaluator = RegressionEvaluator(labelCol='SoundLevelDecibels', predictionCol='prediction', metricName='r2')\n",
    "r2 = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9c1130b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 3 - Evaluation\n",
      "Mean Squared Error =  25.0\n",
      "Mean Absolute Error =  3.91\n",
      "R Squared =  0.5\n",
      "Intercept = 132.88\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 3 - Evaluation\")\n",
    "\n",
    "print(\"Mean Squared Error = \", round(mse,2))\n",
    "print(\"Mean Absolute Error = \", round(mae,2))\n",
    "print(\"R Squared = \", round(r2,2))\n",
    "lrModel = model.stages[-1]\n",
    "print(f\"Intercept = {round(lrModel.intercept,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489ff35e",
   "metadata": {},
   "source": [
    "#### Part 4 (persist the model)\n",
    "1. Save the model.\n",
    "2. Load the model.\n",
    "3. Make prediction on  testing data using loaded model.\n",
    "4. Show predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "65d36c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write().overwrite().save('saved_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "5e8bc353",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = PipelineModel.load('saved_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "b0a1ed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_predictions = loaded_model.transform(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "289f2233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of stages = 3\n",
      "['Frequency', 'AngleOfAttack', 'ChordLength', 'FreeStreamVelocity', 'SuctionSideDisplacement']\n",
      "Coefficients\n",
      "Variable: Frequency with coefficient = -3.9906\n",
      "Variable: AngleOfAttack with coefficient = -2.2881\n",
      "Variable: ChordLength with coefficient = -3.3269\n",
      "Variable: FreeStreamVelocity with coefficient = 1.4832\n",
      "Variable: SuctionSideDisplacement with coefficient = -2.0551\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of stages = {len(loaded_model.stages)}\")\n",
    "input_columns = loaded_model.stages[0].getInputCols()\n",
    "linear_regression_model = loaded_model.stages[-1]\n",
    "print(input_columns)\n",
    "#Print the coefficients of each input variable\n",
    "print('Coefficients')\n",
    "for i,  j in zip(input_columns, linear_regression_model.coefficients):\n",
    "    print(f\"Variable: {i} with coefficient = {round(j,4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "53fcad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark-env (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0b2f79",
   "metadata": {},
   "source": [
    "## Get Started With SparkSQL\n",
    "### What is SparkSQL\n",
    "SparkSQL is a component of apache spark allows users to apply sql queries on spark dataframes. It supports different data types such as:\n",
    "- Hive tables\n",
    "- JSON files\n",
    "- Parquet files\n",
    "- JDBC (Java Database Connectivity)\n",
    "\n",
    "### Steps to use SparkSQL\n",
    "1. Import libraries\n",
    "2. Start spark session\n",
    "3. Load data into a spark dataframe\n",
    "4. Register the dataframe as temporary view\n",
    "5. Perform SQL queries\n",
    "6. Show results\n",
    "7. Finally, stop spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acaa600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import findspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "320818ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/12/10 16:14:28 WARN Utils: Your hostname, omar, resolves to a loopback address: 127.0.1.1; using 192.168.1.4 instead (on interface wlo1)\n",
      "25/12/10 16:14:28 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/10 16:14:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#Start spark session with name (Start with SparkSQL)\n",
    "spark = SparkSession.builder.appName('Start with SparkSQL').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bcd1b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MPG: double (nullable = true)\n",
      " |-- Cylinders: integer (nullable = true)\n",
      " |-- Engine Disp: double (nullable = true)\n",
      " |-- Horsepower: integer (nullable = true)\n",
      " |-- Weight: integer (nullable = true)\n",
      " |-- Accelerate: double (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Load data file into spark dataframe\n",
    "data = spark.read.csv('data/mpg.csv',header=True, inferSchema=True)\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d3ce843",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a temporary view from the dataframe\n",
    "data.createOrReplaceTempView('mileage')      #createOrReplace to replace it if exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9572bc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+-----------+----------+------+----------+----+--------+\n",
      "| MPG|Cylinders|Engine Disp|Horsepower|Weight|Accelerate|Year|  Origin|\n",
      "+----+---------+-----------+----------+------+----------+----+--------+\n",
      "|43.1|        4|       90.0|        48|  1985|      21.5|  78|European|\n",
      "|43.4|        4|       90.0|        48|  2335|      23.7|  80|European|\n",
      "|41.5|        4|       98.0|        76|  2144|      14.7|  80|European|\n",
      "|44.3|        4|       90.0|        48|  2085|      21.7|  80|European|\n",
      "|40.8|        4|       85.0|        65|  2110|      19.2|  80|Japanese|\n",
      "|44.6|        4|       91.0|        67|  1850|      13.8|  80|Japanese|\n",
      "|46.6|        4|       86.0|        65|  2110|      17.9|  80|Japanese|\n",
      "|44.0|        4|       97.0|        52|  2130|      24.6|  82|European|\n",
      "+----+---------+-----------+----------+------+----------+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = 'Select * From mileage Where mpg > 40'\n",
    "result = spark.sql(query)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9593ce",
   "metadata": {},
   "source": [
    "### Do some data analysis on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1cff750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|  Origin|\n",
      "+--------+\n",
      "|European|\n",
      "|Japanese|\n",
      "|American|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('Select distinct Origin From mileage').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28b43bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+\n",
      "|  Origin|Car_count|\n",
      "+--------+---------+\n",
      "|Japanese|       79|\n",
      "+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Count of Japanese cars\n",
    "spark.sql('Select Origin, count(*) as Car_count From mileage Group by Origin Having Origin == \"Japanese\"').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "413973e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|result|\n",
      "+------+\n",
      "|     8|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Count the number of cars with mileage greater than 40\n",
    "spark.sql('Select count(*) as result From mileage  Where mpg  > 40 ').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fc4e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+\n",
      "|Year|number_of_cars|\n",
      "+----+--------------+\n",
      "|  73|            40|\n",
      "|  78|            36|\n",
      "|  76|            34|\n",
      "|  82|            30|\n",
      "|  75|            30|\n",
      "|  70|            29|\n",
      "|  79|            29|\n",
      "|  81|            28|\n",
      "|  72|            28|\n",
      "|  77|            28|\n",
      "|  80|            27|\n",
      "|  71|            27|\n",
      "|  74|            26|\n",
      "+----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#List number of cars made in different years\n",
    "spark.sql('Select Year, count(*) as number_of_cars  from mileage Group by Year Order by number_of_cars desc').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3df3d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark-env (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
